---
layout: post
title: "The connection between Google Glasses and self-driving humanoids"
date: 2012-06-07 09:17
comments: true
categories: [machine-learning, lifelogging, future]
---
[Adrian Holovaty](http://www.holovaty.com/) recently wrote about [the connection between Google Street View and driverless cars](http://www.holovaty.com/writing/streetview/). Towards the end, he wondered whether the decision to record all sensor / locational metadata along with pictures came before the idea of using it to train machine learning algorithms (or vice versa). I'd apply [Occam's razor](http://en.wikipedia.org/wiki/Occam's_razor) here -- i.e., I'm pretty certain the idea of capturing the data came first. 

But what's more interesting is that it presents a whole new angle on what [Project Glass](https://plus.google.com/111626127367496192147) enables: Widespread lifelogging by humans (and not just cars) to cloud-based storage. Add offline speech to text, face recognition, OCR, etc. and you have prosthetic memory.

A tiny step towards "self-driving" humanoids.